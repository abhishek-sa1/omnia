- name: {{ functional_group_name }}
  description: "{{ functional_group_name }} config"
  file:
    encoding: plain
    content: |
      ## template: jinja
      #cloud-config
      merge_how:
      - name: list
        settings: [append]
      - name: dict
        settings: [no_replace, recurse_list]
      users:
        - name: root
          ssh_authorized_keys: "{{ read_ssh_key.stdout }}"
          lock_passwd: false
          hashed_passwd: "{{ hashed_password_output.stdout }}"
      disable_root: false

      write_files:
        - path: /usr/local/bin/set-ssh.sh
          permissions: '0755'
          content: |
            #!/bin/bash
            timedatectl set-timezone {{ hostvars['localhost']['timezone'] }}
            sed -i 's/^#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config
            sed -i 's/^#PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config
            sed -i 's/^PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config.d/50-cloud-init.conf
            systemctl restart sshd
            default_count=$(ip route | grep -c "^default")
            if [ "$default_count" -le 1 ]; then
                echo "Only one or no default route found. No action needed."
            else
                private_nic=$(ip route | grep "^default via {{ hostvars['localhost']['admin_nic_ip'] }}" | awk '{print $5}')
                # Get all default routes
                ip route | grep '^default' | while read -r line; do
                    nmcli con del "Wired Connection"
                    # Extract NIC name
                    nic=$(echo "$line" | awk '{print $5}')

                    # Add the default route to the connection
                    if [ -n "$nic" ]; then
                        echo "Adding nmcli device $nic"
                        nmcli con add type ethernet ifname "$nic" con-name "$nic" ipv4.method auto
                        if [ "$nic" = "$private_nic" ]; then
                          nmcli con modify "$nic" ipv4.never-default yes
                          nmcli con delete "cloud-init $nic"
                        fi
                        nmcli con up "$nic"
                    else
                        echo "No connection found for device $nic"
                    fi
                done
            fi

{% if hostvars['localhost']['openldap_support'] %}
        - path: /etc/sssd/sssd.conf
          owner: root:root
          permissions: '{{ file_mode_600 }}'
          content: |
            {{ lookup('template', 'templates/openldap/sssd.conf.j2') | indent(6) }}

        - path: /usr/local/bin/update_ldap_conf.sh
          owner: root:root
          permissions: '{{ file_mode_755 }}'
          content: |
            {{ lookup('template', 'templates/openldap/update_ldap_conf.sh.j2') | indent(12) }}
{% endif %}

        - path: /etc/hosts
          append: true
          content: |
{% for key in ip_name_map | sort %}
            {{ ip_name_map[key] }} {{ key }}
{% endfor %}


      runcmd:
        - /usr/local/bin/set-ssh.sh
        - groupadd -r {{ slurm_group_name }}
        - useradd -r -g {{ slurm_group_name }} -d {{ home_dir }} -s /sbin/nologin {{ user }}

        - mkdir -p /var/log/slurm /var/run/slurm /var/spool /var/lib/slurm /etc/slurm/epilog.d /etc/munge
        - echo "{{ cloud_init_nfs_path }}/$(hostname -s)/var/log/slurm  /var/log/slurm   nfs defaults,_netdev 0 0" >> /etc/fstab
        - echo "{{ cloud_init_nfs_path }}/$(hostname -s)/var/spool      /var/spool       nfs defaults,_netdev 0 0" >> /etc/fstab
        - echo "{{ cloud_init_nfs_path }}/$(hostname -s)/etc/slurm/epilog.d     /etc/slurm/epilog.d      nfs defaults,_netdev 0 0" >> /etc/fstab
        - echo "{{ cloud_init_nfs_path }}/$(hostname -s)/var/spool      /var/spool       nfs defaults,_netdev 0 0" >> /etc/fstab
        - echo "{{ cloud_init_nfs_path }}/$(hostname -s)/etc/munge      /etc/munge       nfs defaults,_netdev 0 0" >> /etc/fstab
        - chmod {{ file_mode }} /etc/fstab
        - mount -a
        - yes | cp /etc/slurm/epilog.d/slurmd.service /usr/lib/systemd/system/
        - chown -R {{ user }}:{{ slurm_group_name }} /var/log/slurm
        - chown -R {{ user }}:{{ slurm_group_name }} /var/run/slurm
        - chown -R {{ user }}:{{ slurm_group_name }} /var/spool
        - chown -R {{ user }}:{{ slurm_group_name }} /var/lib/slurm
        - chown -R {{ munge_user }}:{{ munge_group }} /etc/munge/munge.key
        - chmod {{ file_mode_755 }} /var/log/slurm /var/run/slurm /var/spool /var/lib/slurm
        - chmod {{ file_mode_400 }} /etc/munge/munge.key
        - chmod {{ file_mode_755 }} /etc/slurm/epilog.d/
        - mkdir -p /var/spool/slurmd
        - chmod {{ file_mode_755 }} /var/spool/slurmd
        - chown -R {{ user }}:{{ slurm_group_name }} /var/spool/slurmd
        - setenforce 0
        - systemctl enable firewalld
        - systemctl start firewalld
        - firewall-cmd --permanent --add-service=ssh
        - firewall-cmd --permanent --add-port={{ slurm_conf_dict.SrunPortRange }}/tcp
        - firewall-cmd --permanent --add-port={{ slurm_conf_dict.SrunPortRange }}/udp
        - firewall-cmd --permanent --add-port={{  slurm_conf_dict.SlurmdPort }}/tcp
        - firewall-cmd --permanent --add-port={{ slurm_conf_dict.SlurmdPort }}/udp
        - firewall-cmd --reload
        - systemctl enable sshd
        - systemctl start sshd
        - systemctl enable munge
        - systemctl start munge
        - systemctl enable slurmd
        - systemctl start slurmd
        - systemctl daemon-reexec
        - systemctl restart sshd

{% if hostvars['localhost']['openldap_support'] %}
        - /usr/local/bin/update_ldap_conf.sh
        - mkdir /ldapcerts
        - echo "{{ cloud_init_nfs_path_openldap }}/certs                /ldapcerts       nfs defaults,_netdev 0 0" >> /etc/fstab
        - echo "{{ cloud_init_nfs_path_openldap }}/ldapuser             /home            nfs defaults,_netdev 0 0" >> /etc/fstab
        - chmod {{ file_mode }} /etc/fstab
        - mount -a
        - yes | cp /ldapcerts/* /etc/openldap/certs
        - umount /ldapcerts

        - firewall-cmd --permanent --add-port={{ ldap_starttls_port }}/tcp
        - firewall-cmd --permanent --add-port={{ ldap_ssl_port }}/tcp
        - firewall-cmd --reload

        - setenforce 0
        - authselect select sssd with-mkhomedir --force
        - sudo systemctl enable --now oddjobd.service
        - sudo systemctl enable --now sssd
        - setsebool -P authlogin_nsswitch_use_ldap on
        - setsebool -P authlogin_yubikey on
        - sudo systemctl restart sssd
        - systemctl restart sshd

{% endif %}

{% if hostvars['localhost']['ucx_support'] or hostvars['localhost']['openmpi_support'] %}
        # Add NFS entry and mount
        - mkdir -p {{ client_mount_path }}
        - echo "{{ nfs_src }} {{ client_mount_path }} nfs defaults,_netdev 0 0" >> /etc/fstab
        - mount -a
{% endif %}

{% if hostvars['localhost']['ucx_support'] %}
        # UCX build and install
        - |
          UCX_BIN={{ client_mount_path }}/benchmarks/ucx
          mkdir -p {{ client_mount_path }}/compile/ucx
          mkdir -p {{ client_mount_path }}/benchmarks/ucx
          cd {{ client_mount_path }}/compile/ucx
          wget --no-check-certificate https://{{ hostvars['localhost']['admin_nic_ip'] }}:2225/pulp/content/opt/omnia/offline_repo/cluster/aarch64/{{ hostvars['localhost']['cluster_os_type'] }}/{{ hostvars['localhost']['cluster_os_version'] }}/tarball/ucx/ucx.tar.gz -O ucx.tar.gz
          tar xzf ucx.tar.gz
          cd ucx-*
          mkdir -p build
          cd build
          ../contrib/configure-release --prefix={{ client_mount_path }}/benchmarks/ucx
          make -j 8
          make install
{% endif %}

{% if hostvars['localhost']['openmpi_support'] %}
        # OpenMPI build and install with UCX + Slurm detection
        - |
          OPENMPI_INSTALL_PREFIX="{{ client_mount_path }}/benchmarks/openmpi"
          OPENMPI_SRC="{{ client_mount_path }}/compile/openmpi"
          mkdir -p $OPENMPI_SRC
          mkdir -p $OPENMPI_INSTALL_PREFIX

          cd $OPENMPI_SRC
          wget --no-check-certificate https://{{ hostvars['localhost']['admin_nic_ip'] }}:2225/pulp/content/opt/omnia/offline_repo/cluster/aarch64/{{ hostvars['localhost']['cluster_os_type'] }}/{{ hostvars['localhost']['cluster_os_version'] }}/tarball/openmpi/openmpi.tar.gz -O openmpi.tar.gz

          tar xzf openmpi.tar.gz
          cd openmpi-*
          mkdir -p build

          # Check Slurm
          if sinfo >/dev/null 2>&1; then
            SLURM_FLAG="--with-slurm=yes"
          else
            SLURM_FLAG="--with-slurm=no"
          fi

          # Check UCX
          if [ -x "{{ client_mount_path }}/benchmarks/ucx/bin/ucx_info" ]; then
            {{ client_mount_path }}/benchmarks/ucx/bin/ucx_info -v
            if [ $? -eq 0 ]; then
              UCX_FLAG="--with-ucx={{ client_mount_path }}/benchmarks/ucx"
            else
              echo "ucx_info failed, disabling UCX"
              UCX_FLAG=""
            fi
          else
            echo "ucx_info not found, disabling UCX"
            UCX_FLAG=""
          fi

          cd build
          ../configure --prefix=$OPENMPI_INSTALL_PREFIX \
            --enable-mpi1-compatibility \
            --enable-prte-prefix-by-default \
            $SLURM_FLAG $UCX_FLAG 2>&1 | tee config.out

          make -j 8
          make install
{% endif %}
