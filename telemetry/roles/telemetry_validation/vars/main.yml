# Copyright 2025 Dell Inc. or its subsidiaries. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

# Usage: validate_telemetry_config.yml
omnia_metadata_file: "/opt/omnia/.data/oim_metadata.yml"
telemetry_config_file: "{{ input_project_dir }}/telemetry_config.yml"
fail_msg_telemetry_config_file: "telemetry_config.yml file doesn't exist."
pause_time_15: 15
bmc_group_data_filename: "/opt/omnia/telemetry/bmc_group_data.csv"
warning_telemetry_support_false: |
  "[WARNING] kube_prometheus_support, idrac_telemetry_support and visualization_support are false in telemetry_config.yml.
  Omnia does not deploy telemetry feature if none of the support category is true."
telemetry_config_syntax_fail_msg: "Failed. Syntax errors present in telemetry_config.yml. Fix errors and re-run playbook again."
warning_idrac_telemetry_support_false: |
  "[WARNING] idrac_telemetry_support is set to false in telemetry_config.yml. This means iDRAC telemetry will not be activated.
  To use telemetry, set idrac_telemetry_support to true in telemetry_config.yml.
  Note that Omnia does not support disabling telemetry if containers are already running.
  To remove telemetry containers, use the utils/oim_cleanup.yml playbook."
warning_idrac_telemetry_support_true: |
  "[WARNING] idrac_telemetry_support is set to true in telemetry_config.yml.
  iDRAC telemetry will be activated for all BMC IPs listed in {{ bmc_group_data_filename }}.
  Confirm that all BMC IPs are reachable from the OIM and respective service cluster nodes for telemetry to function properly.
  Make sure that Redfish is enabled and the iDRAC has a datacenter license.
  Also, ensure that the firmware version is greater than 4 for iDRAC9 or greater than 1 for iDRAC10."

# # Usage: include_provision_config.yml
# provision_config_file: "{{ input_project_dir }}/provision_config.yml"
# fail_msg_provision_config_file: "provision_config.yml file doesn't exist."
# fail_timezone_msg: "Failed. Incorrect timezone provided. Please check the file timezone.txt in discovery/roles/discovery_validations/common/files/ folder."

# Usage: validate_k8s_prometheus.yml
k8s_prom_gaudi_inventory_fail_msg: "Inventory comprising kube_control_plane, kube_node and etcd groups should be passed  \
  when kube_prometheus_support is true in telemetry_config.yml."
kube_control_plane_group_fail_msg: "kube_control_plane group should contain atleast 1 node in inventory"
kube_node_group_fail_msg: "kube_node group should contain atleast 1 node in inventory"
etcd_group_fail_msg: "etcd group should contain atleast 1 node in inventory"
etcd_odd_entry_fail_msg: "etcd group should have odd number of nodes in inventory"

# Usage: validate_image_tars.yml
# noqa: yaml[line-length]
omnia_images_tar_missing_msg: |
  Following images tarball(s) are missing: {{ missing_tars }}.
  To ensure these tar files are present at {{ omnia_images_dir_path }}, execute the utility below:
    `ansible-playbook utils/save_container_images.yml -e 'visualization_support=true idrac_telemetry_support=true k8s_support=true'`
  After saving the images, re-run the telemetry playbook.

# Usage: read_software_config.yml
software_config_file: "{{ input_project_dir }}/software_config.json"
local_repo_service_missing_msg: |
  [ERROR] It seems local_repo not executed with service_k8s entry in software_config.yml.
  Kindly execute local_repo.yml with `service_k8s` entry in softwares list in software_config.json
  and then execute telemetry.yml.
local_repo_access_path: "/opt/omnia/provision/local_repo_access.yml"
k8s_packages_file: "{{ input_project_dir }}/config/{{ software_config.cluster_os_type }}/{{ software_config.cluster_os_version }}/service_k8s.json"
downloaded_sw_log_csv: "/opt/omnia/log/local_repo/software.csv"
software_config_syntax_fail_msg: "Failed. Syntax errors present in software_config.json. Fix errors and re-run playbook again."

# # Usage: validate_prometheus_gaudi.yaml
# fail_msg_k8s_prometheus_support_false: "Failed. k8s_prometheus_support must be true when prometheus_gaudi_support is true in telemetry_config.yml."
# fail_msg_prometheus_gaudi_support: "Failed. prometheus_gaudi_support is only available for cluster_os_type: ubuntu and cluster_os_version: 22.04 , 24.04. \
# Please update prometheus_gaudi_support to false in telemetry_config.yml."

# Usage: validate_idrac_inventory.yml
bmc_group_data_file_not_found_msg: "Failed. The BMC data file: {{ bmc_group_data_filename }} does not exist.
 Please execute discovery_provision.yml to Generate BMC data file."
bmc_group_data_headers: "BMC_IP,GROUP_NAME,PARENT"
bmc_group_data_invalid_msg: "Failed. Invalid BMC data file: {{ bmc_group_data_filename }}.
 Please execute discovery_provision.yml to Generate BMC data file."
bmc_group_data_invalid_ip_msg: "Failed. Invalid BMC IP present in the file: {{ bmc_group_data_filename }}. BMC IP"
bmc_group_data_empty_msg: "Failed. No BMC entries found in BMC group data file {{ bmc_group_data_filename }}."

# Usage: validate_telemetry_container.yml
telemetry_container_status_msg: "Telemetry container Status: {{ telemetry_container_status.containers[0].State.Status }}"
telemetry_container_fail_msg: "Telemetry container {{ telemetry_container }} is not running.
 Current Status: {{ telemetry_container_status.containers[0].State.Status }}"
prepare_oim_telemetry_not_executed_msg: "Telemetry container {{ telemetry_container }} not found.
 Please execute prepare_oim.yml to deploy all required containers."

# Usage: add_host_goups.yml
service_cluster_metadata_path: "/opt/omnia/.data/service_cluster_metadata.yml"
cluster_layout_path: "/opt/omnia/omnia_inventory/cluster_layout"
invalid_parent_tags_message: |
  [ERROR] Invalid parent tags : {{ host_inventory.invalid_parent_tags }}.
  These parent tags found in `{{ bmc_group_data_filename }}` are not of service nodes.
  If your are adding a bmc entry in the csv file, please ensure that the parent tag is service tag of service node.
  If service nodes are not provisioned or compute node provisioning not initiated,
  please run discovery_provision.yml to provision service nodes and compute nodes from service nodes.
  And then run `telemetry.yml` playbook again.
telemetry_host_group: "telemetry_group"
telemetry_host: >-
  {{ groups['kube_control_plane']
     if federated_idrac_telemetry_collection | default(false)
     else ['localhost']
  }}

# Usage: include_high_availability_config.yml
high_availability_config_path: "{{ input_project_dir }}/high_availability_config.yml"
fail_msg_high_availability_config_file: "high_availability_config.yml file doesn't exist."
high_availability_config_syntax_fail_msg: "Failed. Syntax errors present in high_availability_config.yml. Fix errors and re-run playbook again."

# Usage: include_network_spec.yml
network_spec_path: "{{ input_project_dir }}/network_spec.yml"
fail_msg_network_spec_file: "network_spec.yml file doesn't exist."
network_spec_syntax_fail_msg: "Failed. Syntax errors present in network_spec.yml. Fix errors and re-run playbook again."

# Usage: check_service_node_internet.yml
service_cluster_no_internet: "Service Cluster does not have internet access to deploy idrac telemetry collection on service cluster.
      Please enable internet on service cluster and rerun telemetry.yml."

# Usage: validate_telemetry_inventory.yml
enable_federated_telemetry_fail_msg: |
  "It is recommended to set federated_idrac_telemetry_collection to true in telemetry_config.yml, as a service k8s cluster has been provisioned."
telemetry_empty_inventory_fail_msg: |
  "Failed. Either inventory is not provided or inventory does not have required groups. Re-run playbook with inventory by providing -i inventory.
  Required groups in inventory are kube_control_plane, kube_node, etcd"
